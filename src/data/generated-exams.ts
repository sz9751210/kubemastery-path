// Auto-generated by scripts/generate-exams.mjs
import { Lesson } from './types';

export const generatedExams: Record<string, Lesson> = {
  "1": {
    "id": "1",
    "title": "Container Basics",
    "category": "CORE",
    "duration": "20 mins",
    "markdown": "\n# Container Basics: Beyond Docker\n\nTo master Kubernetes, you must strictly understand concepts like **Namespaces**, **Cgroups**, and the **CRI**.\n\n## What is a Container?\nIt's just a process! But it's isolated.\n- **Namespaces**: Isolate what the process *sees* (PID, Network, Mounts).\n- **Cgroups**: Isolate what the process *uses* (CPU, RAM).\n- **Union Filesystem**: Efficient, layered storage (OverlayFS).\n\n## Docker vs CRI\nKubernetes uses the **Container Runtime Interface (CRI)**.\n> [!IMPORTANT]\n> \\`dockershim\\` is dead. You are likely using **containerd** or **CRI-O**. Learn \\`crictl\\`.\n\n\\`\\`\\`bash\n# Check the container runtime version\ncrictl version\n\n# List running containers\ncrictl ps\n\\`\\`\\`\n",
    "tasks": []
  },
  "2": {
    "id": "2",
    "title": "Pod Lifecycle",
    "category": "CORE",
    "duration": "25 mins",
    "markdown": "\n# The Pod Lifecycle\n\nA **Pod** is the atomic unit of K8s. It wraps one or more containers.\n\n## States\n1. **Pending**: Scheduler is finding a node.\n2. **ContainerCreating**: Pulling images.\n3. **Running**: At least one container is up.\n4. **Succeeded/Failed**: Process exited.\n\n\\`\\`\\`bash\n# Create a simple Nginx pod\nkubectl run nginx-demo --image=nginx\n\n# Watch the pod status change\nkubectl get pod nginx-demo -w\n\\`\\`\\`\n",
    "tasks": []
  },
  "3": {
    "id": "3",
    "title": "YAML Configuration",
    "category": "CORE",
    "duration": "30 mins",
    "markdown": "\n# Mastering YAML\n\nKubernetes is **Declarative**. syntax matters.\n\n## The 4 Pillars\n1. **apiVersion**: \\`v1\\`, \\`apps/v1\\`.\n2. **kind**: \\`Pod\\`, \\`Service\\`.\n3. **metadata**: \\`name\\`, \\`labels\\`.\n4. **spec**: The desired state.\n\n\\`\\`\\`yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: demo\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n\\`\\`\\`\n",
    "tasks": []
  },
  "4": {
    "id": "4",
    "title": "Multi-Container Pods",
    "category": "CORE",
    "duration": "35 mins",
    "markdown": "\n# Multi-Container Pods\n\nSharing is caring. Sometimes one container isn't enough.\n\n## Patterns\n1.  **Sidecar**: Helper container (e.g., Log shipper, Proxy).\n2.  **Adapter**: Standardizes output (e.g., Metrics converter).\n3.  **Ambassador**: Proxies connection to outside world.\n\n## Shared Resources\nContainers in a Pod share:\n-   **Network Namespace**: Same IP, same localhost.\n-   **Volumes**: Shared filesystems.\n\n\\`\\`\\`yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sidecar-demo\nspec:\n  containers:\n  - name: main-app\n    image: nginx\n    volumeMounts:\n    - name: shared-logs\n      mountPath: /var/log/nginx\n  - name: log-shipper\n    image: busybox\n    command: [\"sh\", \"-c\", \"tail -f /var/log/nginx/access.log\"]\n    volumeMounts:\n    - name: shared-logs\n      mountPath: /var/log/nginx\n  volumes:\n  - name: shared-logs\n    emptyDir: {}\n\\`\\`\\`\n",
    "tasks": []
  },
  "5": {
    "id": "5",
    "title": "Cluster Architecture",
    "category": "CKA/CKAD",
    "duration": "40 mins",
    "markdown": "\n# Cluster Architecture\n\nUnderstand the machine you are driving.\n\n## The Two Planes\n1.  **Control Plane** (The Brain):\n    -   Manages the state of the cluster.\n    -   Components: API Server, Etcd, Scheduler, Controller Manager.\n2.  **Data Plane** (The Muscle):\n    -   Runs the workloads.\n    -   Components: Kubelet, Kube-Proxy, Container Runtime.\n\n## Kubelet\nThe agent that runs on every node. It registers the node with the apiserver and ensures Pods are running and healthy.\n\n\\`\\`\\`bash\n# Check node status\nkubectl get nodes -o wide\n\\`\\`\\`\n",
    "tasks": []
  },
  "6": {
    "id": "6",
    "title": "Services & Networking",
    "category": "CKA/CKAD",
    "duration": "45 mins",
    "markdown": "\n# Services: Exposing Applications\n\n## Service Types\n1. **ClusterIP**: Internal only.\n2. **NodePort**: Exposure on static port (30000+).\n3. **LoadBalancer**: Cloud provider LB.\n\n\\`\\`\\`bash\n# Expose a deployment\nkubectl expose deployment my-dep --port=80 --target-port=80 --type=NodePort --name=my-svc\n\n# Get the service details\nkubectl get svc my-svc\n\\`\\`\\`\n",
    "tasks": []
  },
  "7": {
    "id": "7",
    "title": "Storage (PV/PVC)",
    "category": "CKA/CKAD",
    "duration": "35 mins",
    "markdown": "\n# Storage Orchestration\n\nDecoupling storage from Pod lifecycle.\n\n## PV vs PVC\n- **PV (PersistentVolume)**: The physical storage resource.\n- **PVC (Claim)**: The request for storage.\n\n\\`\\`\\`bash\n# List Persistent Volumes\nkubectl get pv\n\\`\\`\\`\n\n## Access Modes\n- **RWO**: ReadWriteOnce (Block storage usually).\n- **RWX**: ReadWriteMany (NFS/File storage).\n",
    "tasks": []
  },
  "8": {
    "id": "8",
    "title": "Scheduling",
    "category": "CKA/CKAD",
    "duration": "30 mins",
    "markdown": "\n# Scheduling\n\nControlling where Pods go.\n\n## Taints & Tolerations\n\"Repel\" pods from nodes.\n- Master nodes are tainted \\`NoSchedule\\`.\n\n\\`\\`\\`bash\n# View taints on nodes\nkubectl describe node controlplane | grep Taint\n\\`\\`\\`\n\n## Affinity\n\"Attract\" pods to nodes.\n- \\`nodeAffinity\\`: Run on nodes with SSD.\n",
    "tasks": []
  },
  "9": {
    "id": "9",
    "title": "Cluster Hardening",
    "category": "CKS",
    "duration": "50 mins",
    "markdown": "\n# Cluster Hardening\n\nLocking down the fortress.\n\n## Center for Internet Security (CIS) Benchmarks\nThe gold standard for K8s security. \\`kube-bench\\` is a common tool to check these.\n\n## Key Principles\n1.  **Least Privilege**: RBAC, SecurityContexts.\n2.  **Minimize Attack Surface**: Remove shells, use distroless images.\n3.  **encrypt-secret-data-at-rest**: Check etcd configuration.\n\n## Platform Binary Verification\nEnsure the binaries (kubelet, kubectl, kube-apiserver) are legitimate.\n- Check SHA512 sums against official releases.\n\n## Minimize GUI Use\nThe Kubernetes Dashboard is a frequent attack vector.\n- **Best Practice**: Disable it in production.\n\n\\`\\`\\`bash\n# Check if anonymous auth is enabled (Should be false)\nps -ef | grep kube-apiserver | grep anonymous-auth\n\\`\\`\\`\n",
    "tasks": []
  },
  "10": {
    "id": "10",
    "title": "Network Policies",
    "category": "CKS",
    "duration": "35 mins",
    "markdown": "\n# Network Policies\n\nThe firewall for Kubernetes.\n\n> [!WARNING]\n> By default, K8s is a **Flat Network**. Any pod can talk to any pod.\n\n## Default Deny Logic\nStart by denying everything, then allow specific traffic.\n\n\\`\\`\\`bash\n# See if any policies exist\nkubectl get networkpolicies\n\\`\\`\\`\n",
    "tasks": []
  },
  "11": {
    "id": "11",
    "title": "System Hardening",
    "category": "CKS",
    "duration": "45 mins",
    "markdown": "\n# System Hardening\n\nKubernetes is only as secure as the Linux nodes it runs on.\n\n## Kernel Hardening\n-   **Seccomp**: Restrict syscalls.\n-   **AppArmor**: Restrict file access / capabilities.\n\n## Container Sandboxing\nFor high-risk workloads, standard containers (shared kernel) might not be enough.\n-   **gVisor (runsc)**: Userspace kernel, intercepts syscalls.\n-   **Kata Containers**: Lightweight VMs for strong isolation.\n\n## Reducing Attack Surface\n-   Disable unused services (SSH, FTP).\n-   Firewall rules (UFW/IPTables) to restrict node-to-node access outside of K8s ports.\n\n\\`\\`\\`bash\n# Check open ports on the node\nnetstat -tulpn\n\\`\\`\\`\n",
    "tasks": []
  },
  "12": {
    "id": "12",
    "title": "ReplicaSets & Deployments",
    "category": "CORE",
    "duration": "25 mins",
    "markdown": "\n# ReplicaSets & Deployments\n\nEnsuring your application is always running and easily updated.\n\n## ReplicaSet\nThe primary goal of a **ReplicaSet** is to maintain a stable set of replica Pods running at any given time.\n\n\\`\\`\\`bash\n# Look at the replicasets in your cluster\nkubectl get rs\n\\`\\`\\`\n\n## Deployment\n**Deployments** allow you to manage the rollout of new versions of your application.\n\n\\`\\`\\`bash\n# Create a deployment with 3 replicas\nkubectl create deployment web-server --image=nginx --replicas=3\n\n# Update the image\nkubectl set image deployment/web-server nginx=nginx:1.16.1\n\\`\\`\\`\n",
    "tasks": []
  },
  "13": {
    "id": "13",
    "title": "Jobs & CronJobs",
    "category": "CORE",
    "duration": "20 mins",
    "markdown": "\n# Jobs & CronJobs\n\nFor tasks that are intended to run to completion.\n\n## Jobs\nA **Job** creates one or more Pods and will continue to retry execution of the Pods until a specified number of them successfully terminate.\n\n\\`\\`\\`bash\n# Run a one-off job\nkubectl create job hello --image=busybox -- echo \"Hello Kubernetes\"\n\\`\\`\\`\n\n## CronJobs\nA **CronJob** creates Jobs on a repeating schedule.\n\n\\`\\`\\`bash\n# Create a cronjob\nkubectl create cronjob heartbeat --image=busybox --schedule=\"*/1 * * * *\" -- echo \"Beating...\"\n\\`\\`\\`\n",
    "tasks": []
  },
  "14": {
    "id": "14",
    "title": "Control Plane & API Server",
    "category": "CKA/CKAD",
    "duration": "45 mins",
    "markdown": "\n# Control Plane & API Server\n\nThe brains of the cluster.\n\n## Components\n- **kube-apiserver**: The gateway for all REST commands.\n- **etcd**: Consistent and highly-available key value store.\n- **kube-scheduler**: Watches for newly created Pods with no assigned node.\n- **kube-controller-manager**: Runs controller processes.\n\n\\`\\`\\`bash\n# Check the status of control plane components\nkubectl get pods -n kube-system -l tier=control-plane\n\\`\\`\\`\n",
    "tasks": []
  },
  "15": {
    "id": "15",
    "title": "Troubleshooting & Logs",
    "category": "CKA/CKAD",
    "duration": "40 mins",
    "markdown": "\n# Troubleshooting & Logs\n\nWhen things go wrong, here is how to find out why.\n\n## Basic Commands\n- \\`kubectl describe\\`: Detailed information about a resource.\n- \\`kubectl logs\\`: Print the logs for a container in a pod.\n\n## Common Pod States\n- **Pending**: Scheduler can't find a node (CPU/RAM insufficient, Taints).\n- **CrashLoopBackOff**: Application is starting and immediately failing. Check logs!\n- **ImagePullBackOff**: Can't pull image (Auth, Typo, Network).\n\n## Debugging Services\nService not working? Check the **Endpoints**.\n\\`\\`\\`bash\n# Does the service have endpoints?\nkubectl get endpoints my-svc\n\\`\\`\\`\n\n\\`\\`\\`bash\n# Describe a failing pod\nkubectl describe pod <pod-name>\n\n# Check logs for a specific pod (and previous instance if crashed)\nkubectl logs <pod-name> --previous\n\\`\\`\\`\n",
    "tasks": []
  },
  "16": {
    "id": "16",
    "title": "Admission Controllers",
    "category": "CKS",
    "duration": "50 mins",
    "markdown": "\n# Admission Controllers\n\nIntercepting requests to the API server before an object is persisted.\n\n## Types\n- **Mutating**: Can modify the object.\n- **Validating**: Can only accept or reject.\n\n\\`\\`\\`bash\n# Check which admission plugins are enabled\nkubectl exec -it kube-apiserver-controlplane -n kube-system -- kube-apiserver -h | grep enable-admission-plugins\n\\`\\`\\`\n",
    "tasks": []
  },
  "17": {
    "id": "17",
    "title": "Runtime Security",
    "category": "CKS",
    "duration": "45 mins",
    "markdown": "\n# Runtime Security\n\nProtecting the running process.\n\n## Tools\n- **Falco**: The runtime security engine. Uses rules to detect abnormal behavior (e.g., shell in container, modifying /etc).\n- **AppArmor**: Restrict programs' capabilities with per-program profiles.\n- **Seccomp**: Restrict system calls a process can make.\n\n## Behavioral Analytics\nDetecting threats based on *patterns* rather than known signatures.\n- Process spawning unexpected children.\n- Unexpected outbound network connections.\n",
    "tasks": []
  },
  "18": {
    "id": "18",
    "title": "CRDs & API Extensions",
    "category": "EXPERT",
    "duration": "60 mins",
    "markdown": "\n# CRDs & API Extensions (Deep Dive)\n\nMaking Kubernetes your own.\n\n## Aggregation Layer\nAllows the Kubernetes API server to be extended with additional APIs.\n",
    "tasks": []
  },
  "20": {
    "id": "20",
    "title": "Workloads: Deployments",
    "category": "CKA/CKAD",
    "duration": "45 mins",
    "markdown": "\n# Workloads: Deployments & ReplicaSets\n\nPods are ephemeral. **Deployments** provide declarative updates for Pods and ReplicaSets.\n\n## The Hierarchy\n\\`Deployment\\` manages \\`ReplicaSet\\` manages \\`Pod\\`.\n\n\\`\\`\\`bash\n# Create a deployment\nkubectl create deployment my-dep --image=nginx --replicas=3\n\\`\\`\\`\n\n## Features\n- **Self-healing**: Restarts crashed pods.\n- **Scaling**: \n\\`\\`\\`bash\nkubectl scale deployment my-dep --replicas=5\n\\`\\`\\`\n",
    "tasks": []
  },
  "21": {
    "id": "21",
    "title": "StatefulSets & DaemonSets",
    "category": "CKA/CKAD",
    "duration": "40 mins",
    "markdown": "\n# StatefulSets & DaemonSets\n\nNot everything is a stateless web server.\n\n## StatefulSet\nUsed for databases or apps needing:\n- **Stable Network ID**: \\`web-0\\`, \\`web-1\\`.\n- **Stable Storage**: VolumeClaims templates.\n\n## DaemonSet\nEnsures a copy of a Pod runs on **all** (or some) Nodes.\n- Examples: \\`kube-proxy\\`, \\`fluentd\\` (logging).\n\n\\`\\`\\`bash\n# Check the kube-proxy daemonset\nkubectl get ds -n kube-system\n\\`\\`\\`\n",
    "tasks": []
  },
  "22": {
    "id": "22",
    "title": "Ingress & DNS",
    "category": "CKA/CKAD",
    "duration": "50 mins",
    "markdown": "\n# Ingress & Advanced Networking\n\n**Services** operate at Layer 4 (TCP/UDP). **Ingress** operates at Layer 7 (HTTP/HTTPS).\n\n## Ingress Controller\nAn Ingress resource does nothing without a controller (e.g., Nginx, Traefik).\n\n\\`\\`\\`bash\n# Check for ingress controllers\nkubectl get pods -n ingress-nginx\n\\`\\`\\`\n",
    "tasks": []
  },
  "30": {
    "id": "30",
    "title": "RBAC: Authorization",
    "category": "CKS",
    "duration": "60 mins",
    "markdown": "\n# Role Based Access Control (RBAC)\n\n**Authentication** (Who are you?) vs **Authorization** (What can you do?).\n\n## Core Objects\n1. **Role**: Rules (verbs + resources) scoped to a **Namespace**.\n2. **ClusterRole**: Rules scoped linearly (Cluster-wide).\n3. **RoleBinding**: Connecting a Subject (User/ServiceAccount) to a Role.\n4. **ClusterRoleBinding**: Connecting a Subject to a ClusterRole.\n\n\\`\\`\\`bash\n# Check my permissions\nkubectl auth can-i create pods\n\\`\\`\\`\n",
    "tasks": []
  },
  "31": {
    "id": "31",
    "title": "Secrets Management",
    "category": "CKS",
    "duration": "40 mins",
    "markdown": "\n# Secrets & Security Contexts\n\n## Secrets\nBase64 encoded data. NOT encrypted by default unless EncryptionAtRest is enabled in etcd.\n\n\\`\\`\\`bash\n# Create a generic secret\nkubectl create secret generic my-pass --from-literal=password=secret123\n\\`\\`\\`\n\n## Security Contexts\nDefine privileges and access control for a Pod/Container.\n- \\`runAsUser\\`: UID to run process.\n- \\`fsGroup\\`: GID for volumes.\n",
    "tasks": []
  },
  "40": {
    "id": "40",
    "title": "Helm: Package Management",
    "category": "EXPERT",
    "duration": "50 mins",
    "markdown": "\n# Helm: Kubernetes Package Manager\n\nManaging thousands of YAML files is painful. **Helm** solves this using **Charts**.\n\n## Concepts\n- **Chart**: A bundle of information necessary to create an instance of a Kubernetes application.\n- **Release**: A running instance of a chart.\n\n\\`\\`\\`bash\n# List helm releases\nhelm list -A\n\\`\\`\\`\n",
    "tasks": []
  },
  "41": {
    "id": "41",
    "title": "Operators & CRDs",
    "category": "EXPERT",
    "duration": "60 mins",
    "markdown": "\n# Operators & Custom Resource Definitions (CRDs)\n\nExtending the Kubernetes API.\n\n## CRD (Custom Resource Definition)\nAllows you to define your own API resources.\n\n\\`\\`\\`bash\n# List custom resources\nkubectl get crd\n\\`\\`\\`\n\n## The Operator Pattern\nAn Operator is a Controller that watches a CRD and acts on it.\n",
    "tasks": []
  },
  "42": {
    "id": "42",
    "title": "Service Mesh (Istio)",
    "category": "EXPERT",
    "duration": "60 mins",
    "markdown": "\n# Service Mesh\n\nManaging network traffic between services (East-West traffic).\n\n## Why use a Mesh?\n1. **Observability**: Tracing, Metrics.\n2. **Traffic Control**: Canary types.\n3. **Security**: mTLS.\n\n\\`\\`\\`bash\n# Check for istio proxy sidecars\nkubectl get pods -l istio-injection=enabled\n\\`\\`\\`\n",
    "tasks": []
  },
  "50": {
    "id": "50",
    "title": "Cluster Maintenance",
    "category": "CKA",
    "duration": "45 mins",
    "markdown": "\n# Cluster Maintenance\n\nKeeping the lights on.\n\n## Cluster Upgrade\nUsing \\`kubeadm\\` to upgrade the cluster.\n1.  Upgrade Control Plane node.\n2.  Upgrade Worker nodes.\n\n\\`\\`\\`bash\n# Drain the node first\nkubectl drain node-1 --ignore-daemonsets\n\n# Upgrade kubeadm\napt-get update && apt-get install -y kubeadm=1.27.0-00\n\n# Plan the upgrade\nkubeadm upgrade plan\n\n# Apply\nkubeadm upgrade apply v1.27.0\n\\`\\`\\`\n\n## Backup & Restore\n**Etcd** is the source of truth. You MUST know how to snapshot it.\n\n\\`\\`\\`bash\n# Take a snapshot\nETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \\\\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\\\n  snapshot save /tmp/etcd-backup.db\n\\`\\`\\`\n",
    "tasks": []
  },
  "51": {
    "id": "51",
    "title": "Security & Identity",
    "category": "CKA",
    "duration": "40 mins",
    "markdown": "\n# Security & Identity\n\n## Authentication (AuthN)\nWho are you?\n-   **Certificates**: Most common for users/admins (CN=User, O=Group).\n-   **ServiceAccounts**: For Pods.\n\n\\`\\`\\`bash\n# Create a CSR (CertificateSigningRequest)\nkubectl create -f my-user-csr.yaml\nkubectl certificate approve my-user\n\\`\\`\\`\n\n## Authorization (AuthZ) & RBAC\nWhat can you do?\nSee 'RBAC: Authorization' lesson for details. Kubeadm enables Node and RBAC authorizers by default.\n",
    "tasks": []
  },
  "52": {
    "id": "52",
    "title": "Advanced Storage",
    "category": "CKA/CKAD",
    "duration": "35 mins",
    "markdown": "\n# Advanced Storage\n\n## Storage Class\nDefines \"classes\" of storage (e.g., \"fast\", \"slow\"). Enables **Dynamic Provisioning**.\n\n\\`\\`\\`yaml\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: fast\nprovisioner: k8s.io/minikube-hostpath\n\\`\\`\\`\n\n## Dynamic Provisioning\nInstead of creating a PV manually, creating a PVC with a \\`storageClassName\\` triggers the provisioner to create the PV automatically.\n",
    "tasks": []
  },
  "53": {
    "id": "53",
    "title": "Cluster Networking",
    "category": "CKA",
    "duration": "50 mins",
    "markdown": "\n# Cluster Networking\n\n## CNI (Container Network Interface)\nThe plugin that configures network interfaces.\n-   **Flannel, Calico, Weave**.\n-   Every Pod gets a unique IP.\n\n## DNS (CoreDNS)\nService discovery.\n-   Service: \\`my-svc.my-ns.svc.cluster.local\\`\n-   Pod: \\`1-2-3-4.my-ns.pod.cluster.local\\`\n\n\\`\\`\\`bash\n# Debug DNS\nkubectl run busybox --image=busybox:1.28 --restart=Never -- sleep 3600\nkubectl exec -it busybox -- nslookup kubernetes\n\\`\\`\\`\n",
    "tasks": []
  },
  "54": {
    "id": "54",
    "title": "Observability",
    "category": "CKA",
    "duration": "30 mins",
    "markdown": "\n# Observability\n\n## Metrics Server\nAggregates resource usage data. Required for \\`kubectl top\\` and HPA (Horizontal Pod Autoscaler).\n\n\\`\\`\\`bash\n# Check node usage\nkubectl top nodes\n\n# Check pod usage\nkubectl top pods\n\\`\\`\\`\n\n## Logging architecture\n-   **Node level**: \\`/var/log/containers\\`\n-   **Cluster level**: Fluentd/Prometheus stack (usually).\n",
    "tasks": []
  },
  "60": {
    "id": "60",
    "title": "Supply Chain Security",
    "category": "CKS",
    "duration": "45 mins",
    "markdown": "\n# Supply Chain Security\n\nSecuring the pipeline from code to cluster.\n\n## Image Scanning\nFind vulnerabilities (CVEs) in your images *before* they run.\n- **Tools**: Trivy, Clair.\n- **Action**: Fix Critical/High CVEs.\n\n\\`\\`\\`bash\n# Scan an image with Trivy\ntrivy image nginx:latest\n\\`\\`\\`\n\n## Image Signing\nProve the image comes from you and hasn't been tampered with.\n- **Cosign (Sigstore)**: Sign and verify container images.\n\n## Static Analysis\nScan your YAML manifests for misconfigurations.\n- **Kubesec**: Security risk analysis for Kubernetes resources.\n- **KubeLinter**: Static analysis tool.\n",
    "tasks": []
  },
  "61": {
    "id": "61",
    "title": "Audit Logging & Monitoring",
    "category": "CKS",
    "duration": "50 mins",
    "markdown": "\n# Audit Logging & Monitoring\n\nIf you didn't log it, it didn't happen.\n\n## Audit Logs\nRecords the sequence of actions taken by the cluster (API Server).\n- **Stages**: RequestReceived, ResponseStarted, ResponseComplete, Panic.\n- **Policy**: Defines rules for what to log and how much detail.\n\n\\`\\`\\`yaml\n# audit-policy.yaml example\napiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n  - level: Metadata\n    resources:\n    - group: \"\"\n      resources: [\"secrets\"]\n\\`\\`\\`\n\n## Monitoring (Syscall)\nUsing **Falco** to monitor system calls at the kernel level.\n- Detects: File access, Process execution, Network activity.\n",
    "tasks": []
  },
  "62": {
    "id": "62",
    "title": "Advanced Pod Security",
    "category": "CKS",
    "duration": "45 mins",
    "markdown": "\n# Advanced Pod Security\n\n## Pod Security Standards (PSS)\nReplaced PodSecurityPolicies (PSP). Defined in 3 levels:\n1. **Privileged**: Unrestricted (Admin level).\n2. **Baseline**: Minimally restrictive (Default).\n3. **Restricted**: Heavily restricted (Best practice).\n\n## Pod Security Admission (PSA)\nThe built-in admission controller to enforce PSS via Namespace labels.\n\n\\`\\`\\`bash\n# Enforce restricted standard on 'dev' namespace\nkubectl label ns dev pod-security.kubernetes.io/enforce=restricted\n\\`\\`\\`\n\n## mTLS (Mutual TLS)\nEncrypting traffic *between* pods.\n- Usually handled by a Service Mesh (Linkerd, Istio), but understanding the concept is key for CKS.\n",
    "tasks": []
  },
  "70": {
    "id": "70",
    "title": "Application Build & Images",
    "category": "CKAD",
    "duration": "40 mins",
    "markdown": "\n# Application Build & Images\n\n## Dockerfile Best Practices\n- **Multi-stage builds**: Keep the final image small by separating build and runtime environments.\n- **User Permissions**: Never run as root. Use \\`USER\\`.\n- **Layers**: Combine commands to reduce layers.\n\n\\`\\`\\`dockerfile\n# Multi-stage example\nFROM golang:1.21 as builder\nWORKDIR /app\nCOPY . .\nRUN go build -o myapp\n\nFROM alpine:latest\nWORKDIR /root/\nCOPY --from=builder /app/myapp .\nCMD [\"./myapp\"]\n\\`\\`\\`\n",
    "tasks": []
  },
  "71": {
    "id": "71",
    "title": "Advanced Deployment Strategies",
    "category": "CKAD",
    "duration": "50 mins",
    "markdown": "\n# Advanced Deployment Strategies\n\n## Blue/Green Deployment\n- Two identical environments.\n- **Switch**: Update the Service selector to point to the new version.\n- **Pros**: Instant rollback. **Cons**: Double resources.\n\n## Canary Deployment\n- Roll out to a small subset of users.\n- **Implementation**: Two Deployments (Stable & Canary) with common labels targeted by one Service.\n- **Traffic Splitting**: Use Ingress or Service Mesh for % based splitting.\n\n## Rolling Update\n- Default strategy.\n- **Parameters**: \\`maxSurge\\` (how many extra) and \\`maxUnavailable\\` (how many down).\n",
    "tasks": []
  },
  "72": {
    "id": "72",
    "title": "Application Observability",
    "category": "CKAD",
    "duration": "45 mins",
    "markdown": "\n# Application Observability\n\n## Probes\nKubelet needs to know if your app is okay.\n1.  **Liveness**: Restart if dead (deadlock).\n2.  **Readiness**: Don't send traffic until ready (loading data).\n3.  **Startup**: Wait for slow starts before other probes kick in.\n\n\\`\\`\\`yaml\nlivenessProbe:\n  httpGet:\n    path: /healthz\n    port: 8080\n  initialDelaySeconds: 3\n  periodSeconds: 3\n\\`\\`\\`\n\n## Debugging\n- **Logs**: \\`kubectl logs my-pod -c my-container\\`\n- **Exec**: \\`kubectl exec -it my-pod -- sh\\`\n- **Ephemeral Containers**: \\`kubectl debug -it my-pod --image=busybox --target=my-container\\` (Great for distroless images).\n",
    "tasks": []
  },
  "73": {
    "id": "73",
    "title": "Services & Networking Design",
    "category": "CKAD",
    "duration": "40 mins",
    "markdown": "\n# Services & Networking Design\n\n## Network Policies\nIsolate your applications.\n- **Ingress**: Incoming traffic.\n- **Egress**: Outgoing traffic.\n\n## Service Discovery\n- **DNS**: Every Service gets a DNS name.\n- **Debugging DNS**: Use \\`nslookup\\` or \\`dig\\` from within a pod.\n\n\\`\\`\\`bash\n# Test connectivity\nkubectl run test --rm -it --image=busybox -- wget -O- http://my-service\n\\`\\`\\`\n",
    "tasks": []
  },
  "90": {
    "id": "90",
    "title": "Command Line Fu: JSONPath",
    "category": "CKA/CKAD",
    "duration": "45 mins",
    "markdown": "\n# Command Line Fu: JSONPath & Custom Columns\n\nMastering \\`kubectl\\` output is mandatory for CKA/CKAD.\n\n## JSONPath\nFilter and format output programmatically.\n- **Syntax**: \\`{.items[*].metadata.name}\\`\n\n\\`\\`\\`bash\n# Get all pod names\nkubectl get pods -o jsonpath='{.items[*].metadata.name}'\n\n# Get InternalIP of all nodes\nkubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type==\"InternalIP\")].address}'\n\\`\\`\\`\n\n## Custom Columns\nCreate your own table output.\n\\`\\`\\`bash\n# Show Pod Name and Node Name\nkubectl get pods -o custom-columns=POD:.metadata.name,NODE:.spec.nodeName\n\\`\\`\\`\n",
    "tasks": []
  },
  "91": {
    "id": "91",
    "title": "Cluster Bootstrap Deep Dive",
    "category": "CKA",
    "duration": "60 mins",
    "markdown": "\n# Cluster Bootstrap: Kubeadm\n\nUnderstanding how the cluster comes alive.\n\n## The Init Process (\\`kubeadm init\\`)\n1.  **Pre-flight checks**: Kernel version, Swap disabled?\n2.  **Certs**: Generates CA, API server, Etcd certs in \\`/etc/kubernetes/pki\\`.\n3.  **Kubeconfigs**: Generates admin.conf, kubelet.conf.\n4.  **Manifests**: Static pods for Control Plane (API, Controller, Sched, Etcd) in \\`/etc/kubernetes/manifests\\`.\n5.  **Taints**: Marks node as ControlPlane (NoSchedule).\n6.  **Bootstrap Token**: For workers to join.\n\n## CNI Installation\nThe cluster is **NotReady** until a CNI (Network Plugin) is installed.\n- The CNI binaires go to \\`/opt/cni/bin\\`.\n- The config goes to \\`/etc/cni/net.d\\`.\n",
    "tasks": []
  },
  "99": {
    "id": "99",
    "title": "Chaos Challenge: The Broken Cluster",
    "category": "EXPERT",
    "duration": "60 mins",
    "markdown": "\n# Chaos Challenge: The Broken Cluster\n\n> [!WARNING]\n> This is a **live fire** exercise. We have deliberately broken this cluster.\n\n## Scenario\nYou are the on-call Site Reliability Engineer. Minutes ago, all \\`kubectl\\` commands started failing.\n\n## Your Mission\n1.  **Diagnose** why the API Server is failing.\n2.  **Fix** the underlying issue.\n3.  **Restore** cluster connectivity.\n",
    "tasks": []
  },
  "100": {
    "id": "100",
    "title": "Service Internals: Iptables vs IPVS",
    "category": "INTERNALS",
    "duration": "60 mins",
    "markdown": "\n# Service Implementation: Deep Dive\n\nHow does a Service IP (ClusterIP) actually work? It's virtual! It doesn't exist on any interface.\n\n## kube-proxy\nThe component responsible for watching the API Server for Services/Endpoints and configuring rules.\n\n## Iptables Mode (Default)\nTraffic is captured by PREROUTING/OUTPUT chains and redirected.\n- **Chain KUBE-SERVICES**: The entry point.\n- **Chain KUBE-SVC-***: Round-robin load balancing (using statistic mode random probability).\n- **Chain KUBE-SEP-***: Service EndPoint (DNAT to actual Pod IP).\n\n\\`\\`\\`bash\n# View service rules\nsudo iptables -t nat -L KUBE-SERVICES\n\\`\\`\\`\n\n## IPVS Mode\nUses Linux Kernel's IP Virtual Server (Netfilter).\n- **Performance**: O(1) matching vs O(n) for iptables (sequential scan).\n- **Scalability**: Better for thousands of services.\n",
    "tasks": []
  },
  "101": {
    "id": "101",
    "title": "CNI Deep Dive: Pod Networking",
    "category": "INTERNALS",
    "duration": "75 mins",
    "markdown": "\n# CNI Deep Dive\n\nHow do Pods talk to each other across nodes?\n\n## The \"Pause\" Container\nExists solely to hold the Network Namespace. Application containers join this namespace (share localhost).\n\n## VETH Pairs (Virtual Ethernet)\nConnects the Pod namespace to the Host namespace.\n- **eth0 (Pod)** <--> **veth*** (Host).\n\n## Bridge Mode (e.g., cbr0)\nVETH ends on the host are connected to a Bridge. The Bridge acts as a virtual switch.\n\n## Overlay Networks (VXLAN / IPIP)\nEncapsulating L2 frames inside L3 packets to cross node boundaries.\n- **Flannel**: UDP/VXLAN.\n- **Calico**: BGP (Direct Routing) or IPIP.\n",
    "tasks": []
  },
  "102": {
    "id": "102",
    "title": "Etcd & Raft Consensus",
    "category": "INTERNALS",
    "duration": "60 mins",
    "markdown": "\n# Etcd & The Raft Consensus Algorithm\n\nHow does Kubernetes maintain a consistent state across multiple control plane nodes? It relies entirely on **Etcd**.\n\n## What is Etcd?\nEtcd is a distributed, reliable key-value store. It is the \"source of truth\" for Kubernetes.\n\n## The Raft Algorithm\nEtcd uses **Raft** to achieve consensus.\n1.  **Leader Election**: One node is elected leader. All writes go to the leader.\n2.  **Log Replication**: The leader replicates the entry to followers.\n3.  **Commit**: Once a majority (Quorum) acknowledges the entry, it is committed.\n\n### Quorum\n$N/2 + 1$. For a 3-node cluster, you need 2 nodes to agree.\n-   **3 Nodes**: Tolerate 1 failure.\n-   **5 Nodes**: Tolerate 2 failures.\n\n```bash\n# Check endpoint health\nETCDCTL_API=3 etcdctl endpoint health\n```\n",
    "tasks": []
  },
  "103": {
    "id": "103",
    "title": "The Controller Pattern",
    "category": "INTERNALS",
    "duration": "70 mins",
    "markdown": "\n# The Controller Pattern & Reconciliation Loop\n\nKubernetes is a system of **eventually consistent** control loops.\n\n## The Loop\n1.  **Observe**: Watch the current state (via API Server).\n2.  **Diff**: Compare against desired state (Spec).\n3.  **Act**: Make changes to move closer to desired state.\n\n## Under the Hood (client-go)\nHow does a controller actually work?\n1.  **Reflector**: Watches the API and puts objects in a localized Queue (`DeltaFIFO`).\n2.  **Informer**: Reads from Queue and updates the **Local Store (Cache)**. This avoids hammering the API server.\n3.  **Workqueue**: When an object changes, its key (e.g., `default/my-pod`) is added here.\n4.  **Reconciler**: The worker logic that pops the key and does the business logic.\n\n> [!NOTE]\n> This is why \"Level Triggered\" logic is preferred over \"Edge Triggered\". If you miss an event, you just reconcile the current state next time.\n",
    "tasks": []
  },
  "104": {
    "id": "104",
    "title": "OCI & Low-Level Runtimes",
    "category": "INTERNALS",
    "duration": "60 mins",
    "markdown": "\n# OCI & RunC: How a Container Starts\n\nWhen you ask K8s to run a Pod, `kubelet` calls the CRI (e.g., `containerd`). But what does `containerd` do?\n\n## The OCI (Open Container Initiative)\nIt defines two specs:\n1.  **Image Spec**: How the filesystem and metadata are bundled.\n2.  **Runtime Spec**: `config.json` that defines *how* to run it (namespaces, cgroups, commands).\n\n## The Flow\n`Kubelet` -> `CRI (containerd)` -> `Shim (containerd-shim)` -> `OCI Runtime (runc)` -> `Kernel`.\n\n### What is runc?\nIt is a CLI tool for spawning and running containers according to the OCI spec. It interacts directly with Linux kernel features like:\n-   **unshare**: To create namespaces.\n-   **cgroups**: To set limits.\n-   **pivot_root**: To change the root filesystem.\n\n```bash\n# You can run a container manually with runc!\nmkdir -p mycontainer/rootfs\n# Export a docker image to rootfs...\nrunc spec # Generates config.json\nrunc run mycontainer\n```\n",
    "tasks": []
  },
  "201": {
    "id": "201",
    "title": "CKA Mock Exam 1",
    "category": "CKA",
    "duration": "120 mins",
    "markdown": "\n# CKA Mock Exam 1\n\nTime: 2 Hours. Pass: 66%.\n\n## Task 1: Backup Etcd\nSave a snapshot of etcd to \\`/opt/etcd-backup.db\\`.\n\n## Task 2: Upgrade Master Node\nUpgrade the controlplane node to version \\`1.27.0\\`.\n\n## Task 3: Create a Pod with Sidecar\nCreate a pod named \\`legacy-app\\` with image \\`busybox\\` that logs to \\`/var/log/legacy.log\\`. Add a sidecar container that prints this log file to stdout.\n\n## Task 4: Troubleshoot Node\nNode \\`worker-1\\` is NotReady. Fix it.\n",
    "tasks": []
  },
  "202": {
    "id": "202",
    "title": "CKA Mock Exam 2",
    "category": "CKA",
    "duration": "120 mins",
    "markdown": "\n# CKA Mock Exam 2\n\nTime: 2 Hours. Pass: 66%.\n\n## Task 1: Network Policy\nCreate a NetworkPolicy named \\`deny-all\\` in namespace \\`probation\\` that denies all ingress traffic.\n\n## Task 2: RBAC\nCreate a Role \\`developer\\` that can \\`create\\`, \\`get\\`, \\`list\\` pods in namespace \\`dev\\`. Bind it to user \\`jane\\`.\n\n## Task 3: Ingress\nExpose service \\`frontend\\` on path \\`/store\\` using an Ingress resource.\n\n## Task 4: Persistent Volume\nCreate a PV named \\`local-pv\\` with capacity \\`1Gi\\`, access mode \\`RWO\\`, hostPath \\`/mnt/data\\`.\n",
    "tasks": []
  },
  "cka-mock-auto-01": {
    "id": "cka-mock-auto-01",
    "title": "Automated CKA Mock Exam 1",
    "category": "CKA",
    "duration": "120 mins",
    "markdown": "\n# Task 1: Create a Pod\nCreate a pod named `nginx` with image `nginx`.\n\n```bash\nkubectl run nginx --image=nginx\n```\n\n# Task 2: Service Limit\nCreate a service named `my-service` of type `NodePort`.\n",
    "tasks": [
      "# Task 1: Create a Pod\nCreate a pod named `nginx` with image `nginx`.\n\n```bash\nkubectl run nginx --image=nginx\n```\n\n",
      "# Task 2: Service Limit\nCreate a service named `my-service` of type `NodePort`.\n"
    ]
  },
  "cka-mock-02": {
    "id": "cka-mock-02",
    "title": "CKA Mock Exam 2 (Pool)",
    "category": "CKA",
    "duration": "120 mins",
    "markdown": "\n# Task 1: ETCD Snapshot\nCreate a snapshot of the etcd instance running on the controlplane node.\nSave it to /opt/etcd-backup.db.\n\n```bash\nETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\n  snapshot save /opt/etcd-backup.db\n```\n\n# Task 2: Fix a broken node\nThe node `worker-1` is in `NotReady` state. Investigate why and fix it.\nCheck `systemctl status kubelet`.\n\n# Task 3: Ingress Resource\nCreate an ingress named `my-ingress` that routes path `/hello` to service `hello-service` on port 80.\n\n# Task 4: Private Registry Secret\nCreate a secret named `my-registry-key` of type `docker-registry` with username `user` and password `pass`.\nThen patch the default service account to use it.\n",
    "tasks": [
      "# Task 1: ETCD Snapshot\nCreate a snapshot of the etcd instance running on the controlplane node.\nSave it to /opt/etcd-backup.db.\n\n```bash\nETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \\\n  --cacert=/etc/kubernetes/pki/etcd/ca.crt \\\n  --cert=/etc/kubernetes/pki/etcd/server.crt \\\n  --key=/etc/kubernetes/pki/etcd/server.key \\\n  snapshot save /opt/etcd-backup.db\n```\n\n",
      "# Task 2: Fix a broken node\nThe node `worker-1` is in `NotReady` state. Investigate why and fix it.\nCheck `systemctl status kubelet`.\n\n",
      "# Task 3: Ingress Resource\nCreate an ingress named `my-ingress` that routes path `/hello` to service `hello-service` on port 80.\n\n",
      "# Task 4: Private Registry Secret\nCreate a secret named `my-registry-key` of type `docker-registry` with username `user` and password `pass`.\nThen patch the default service account to use it.\n"
    ]
  },
  "cka-mock-03": {
    "id": "cka-mock-03",
    "title": "CKA Mock Exam 3 (Pool)",
    "category": "CKA",
    "duration": "120 mins",
    "markdown": "\n# Task 1: Node Affinity\nCreate a deployment `nginx` with 2 replicas. Ensure they land on nodes with label `disk=ssd`.\n\n# Task 2: Sidecar Container\nEdit the pod `logging-pod`. Add a sidecar container image `busybox` that runs `tail -f /var/log/app.log`.\nThe volume `log-volume` is already mounted at `/var/log`.\n\n# Task 3: ClusterUpgrade\nUpgrade the control plane to version 1.29.0.\nRemember to drain the node first!\n\n# Task 4: Network Policy Access\nAllow traffic from pods with label `role=frontend` to pods with label `role=backend` on port 80.\nDeny all other ingress traffic to backend.\n",
    "tasks": [
      "# Task 1: Node Affinity\nCreate a deployment `nginx` with 2 replicas. Ensure they land on nodes with label `disk=ssd`.\n\n",
      "# Task 2: Sidecar Container\nEdit the pod `logging-pod`. Add a sidecar container image `busybox` that runs `tail -f /var/log/app.log`.\nThe volume `log-volume` is already mounted at `/var/log`.\n\n",
      "# Task 3: ClusterUpgrade\nUpgrade the control plane to version 1.29.0.\nRemember to drain the node first!\n\n",
      "# Task 4: Network Policy Access\nAllow traffic from pods with label `role=frontend` to pods with label `role=backend` on port 80.\nDeny all other ingress traffic to backend.\n"
    ]
  }
};
